{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession # main entry point for DataFrame and Sql functionlaity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark=SparkSession.builder.appName('Example2020').master('local').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------+--------------+--------------+-----------------+--------------------+-------------+--------------+----------------+\n",
      "|customer_id|customer_fname|customer_lname|customer_email|customer_password|     customer_street|customer_city|customer_state|customer_zipcode|\n",
      "+-----------+--------------+--------------+--------------+-----------------+--------------------+-------------+--------------+----------------+\n",
      "|          1|       Richard|     Hernandez|     XXXXXXXXX|        XXXXXXXXX|  6303 Heather Plaza|  Brownsville|            TX|           78521|\n",
      "|          2|          Mary|       Barrett|     XXXXXXXXX|        XXXXXXXXX|9526 Noble Embers...|    Littleton|            CO|           80126|\n",
      "|          3|           Ann|         Smith|     XXXXXXXXX|        XXXXXXXXX|3422 Blue Pioneer...|       Caguas|            PR|           00725|\n",
      "|          4|          Mary|         Jones|     XXXXXXXXX|        XXXXXXXXX|  8324 Little Common|   San Marcos|            CA|           92069|\n",
      "|          5|        Robert|        Hudson|     XXXXXXXXX|        XXXXXXXXX|10 Crystal River ...|       Caguas|            PR|           00725|\n",
      "+-----------+--------------+--------------+--------------+-----------------+--------------------+-------------+--------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parquet=spark.read.parquet(\"file:///SparkCourse/01_Datasets/customer_parq.parquet\")\n",
    "parquet.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### createDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [('James','','Smith','1991-04-01','M',3000),('Michael','Rose','','2000-05-19','M',4000),('Robert','','Williams','1978-09-05','M',4000),('Maria','Anne','Jones','1967-12-01','F',4000),('Jen','Mary','Brown','1980-02-17','F',-1)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+---------+-------------+------+------+\n",
      "|First_Name|Middle_Name|Last_Name|Date_of_Birth|Gender|Salary|\n",
      "+----------+-----------+---------+-------------+------+------+\n",
      "|     James|           |    Smith|   1991-04-01|     M|  3000|\n",
      "|   Michael|       Rose|         |   2000-05-19|     M|  4000|\n",
      "|    Robert|           | Williams|   1978-09-05|     M|  4000|\n",
      "|     Maria|       Anne|    Jones|   1967-12-01|     F|  4000|\n",
      "|       Jen|       Mary|    Brown|   1980-02-17|     F|    -1|\n",
      "+----------+-----------+---------+-------------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df=spark.createDataFrame(data,schema=['First_Name','Middle_Name','Last_Name','Date_of_Birth','Gender','Salary'])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- First_Name: string (nullable = true)\n",
      " |-- Middle_Name: string (nullable = true)\n",
      " |-- Last_Name: string (nullable = true)\n",
      " |-- Date_of_Birth: string (nullable = true)\n",
      " |-- Gender: string (nullable = true)\n",
      " |-- Salary: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dataframe from RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"language\",\"users_count\"]\n",
    "data = [(\"Java\", \"20000\"), (\"Python\", \"100000\"), (\"Scala\", \"3000\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf=SparkSession.builder.appName('dataframe_example1').master('local').getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.RDD"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd=conf.sparkContext.parallelize(data)\n",
    "type(rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+\n",
      "|language|user_count|\n",
      "+--------+----------+\n",
      "|    Java|     20000|\n",
      "|  Python|    100000|\n",
      "|   Scala|      3000|\n",
      "+--------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfrdd=rdd.toDF(schema=['language','user_count'])\n",
    "dfrdd.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+\n",
      "|language|users_count|\n",
      "+--------+-----------+\n",
      "|    Java|      20000|\n",
      "|  Python|     100000|\n",
      "|   Scala|       3000|\n",
      "+--------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rowData = map(lambda x: Row(*x),data) \n",
    "dfFromData3 = spark.createDataFrame(rowData,columns)\n",
    "dfFromData3.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create pyspark using schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType,StructField,StringType,IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = [(\"James\",\"\",\"Smith\",\"36636\",\"M\",3000),(\"Michael\",\"Rose\",\"\",\"40288\",\"M\",4000),(\"Robert\",\"\",\"Williams\",\"42114\",\"M\",4000),\n",
    "    (\"Maria\",\"Anne\",\"Jones\",\"39192\",\"F\",4000),(\"Jen\",\"Mary\",\"Brown\",\"\",\"F\",-1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Schema=StructType([StructField('Firstname',StringType(),True),StructField('Middlename',StringType(),True),StructField('Lastname',StringType(),True),StructField('Id',StringType(),True),StructField('Gender',StringType(),True),StructField('Salary',IntegerType(),True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------+-----+------+------+\n",
      "|Firstname|Middlename|Lastname|   Id|Gender|Salary|\n",
      "+---------+----------+--------+-----+------+------+\n",
      "|    James|          |   Smith|36636|     M|  3000|\n",
      "|  Michael|      Rose|        |40288|     M|  4000|\n",
      "|   Robert|          |Williams|42114|     M|  4000|\n",
      "|    Maria|      Anne|   Jones|39192|     F|  4000|\n",
      "|      Jen|      Mary|   Brown|     |     F|    -1|\n",
      "+---------+----------+--------+-----+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_schema=spark.createDataFrame(data=data2,schema=Schema)\n",
    "df_schema.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating DataFrame from other sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Schema1=StructType([StructField('Id',StringType(),True),StructField('Date_of_year',StringType(),True),StructField('Temp_max',StringType(),True),StructField('Temp',IntegerType(),True),StructField('Gender',StringType(),True),StructField('Salary',StringType(),True),StructField('Salary1',StringType(),True),StructField('Salary3',StringType(),True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------+--------+----+------+------+-------+-------+\n",
      "|         Id|Date_of_year|Temp_max|Temp|Gender|Salary|Salary1|Salary3|\n",
      "+-----------+------------+--------+----+------+------+-------+-------+\n",
      "|ITE00100554|    18000101|    TMAX| -75|  null|  null|      E|   null|\n",
      "|ITE00100554|    18000101|    TMIN|-148|  null|  null|      E|   null|\n",
      "|GM000010962|    18000101|    PRCP|   0|  null|  null|      E|   null|\n",
      "|EZE00100082|    18000101|    TMAX| -86|  null|  null|      E|   null|\n",
      "|EZE00100082|    18000101|    TMIN|-135|  null|  null|      E|   null|\n",
      "|ITE00100554|    18000102|    TMAX| -60|  null|     I|      E|   null|\n",
      "|ITE00100554|    18000102|    TMIN|-125|  null|  null|      E|   null|\n",
      "|GM000010962|    18000102|    PRCP|   0|  null|  null|      E|   null|\n",
      "|EZE00100082|    18000102|    TMAX| -44|  null|  null|      E|   null|\n",
      "|EZE00100082|    18000102|    TMIN|-130|  null|  null|      E|   null|\n",
      "|ITE00100554|    18000103|    TMAX| -23|  null|  null|      E|   null|\n",
      "|ITE00100554|    18000103|    TMIN| -46|  null|     I|      E|   null|\n",
      "|GM000010962|    18000103|    PRCP|   4|  null|  null|      E|   null|\n",
      "|EZE00100082|    18000103|    TMAX| -10|  null|  null|      E|   null|\n",
      "|EZE00100082|    18000103|    TMIN| -73|  null|  null|      E|   null|\n",
      "|ITE00100554|    18000104|    TMAX|   0|  null|  null|      E|   null|\n",
      "|ITE00100554|    18000104|    TMIN| -13|  null|  null|      E|   null|\n",
      "|GM000010962|    18000104|    PRCP|   0|  null|  null|      E|   null|\n",
      "|EZE00100082|    18000104|    TMAX| -55|  null|  null|      E|   null|\n",
      "|EZE00100082|    18000104|    TMIN| -74|  null|  null|      E|   null|\n",
      "+-----------+------------+--------+----+------+------+-------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df11=spark.read.csv(path='file:///SparkCourse/1800.csv',schema=Schema1)\n",
    "df11.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Text File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               value|\n",
      "+--------------------+\n",
      "|01,senthil,parace...|\n",
      "|02,saravanan,avil...|\n",
      "|03,rajesh,metacin...|\n",
      "|04,usha,paracetam...|\n",
      "|05,alex,paracetam...|\n",
      "|06,nasir,metacin,...|\n",
      "|07,singh,paraceta...|\n",
      "|08,santhosh,parac...|\n",
      "|09,sarah,avil,fem...|\n",
      "|10,raj,metacin,ma...|\n",
      "|11,uday,crocin,ma...|\n",
      "|12,alexander,anac...|\n",
      "|13,nimrat,metacin...|\n",
      "|14,shiva,paraceta...|\n",
      "|15,senthilnathan,...|\n",
      "|16,saravanan,avil...|\n",
      "|17,ramkumar,croci...|\n",
      "|18,sandhya,lanoxi...|\n",
      "|19,madan,lanoxin,...|\n",
      "|20,kavitha,metaci...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df22=spark.read.text('file:///SparkCourse/01_Datasets/data_10.txt')\n",
    "df22.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+--------+----+----------+\n",
      "|  Address|Boolean|  Mobile|Name|      Pets|\n",
      "+---------+-------+--------+----+----------+\n",
      "|[USA, AU]|   true|12345678|Test|[Dog, cat]|\n",
      "+---------+-------+--------+----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df33=spark.read.json('file:///SparkCourse/01_Datasets/json_sample.json')\n",
    "df33.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pyspark read and write Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.parquet(\"file:///SparkCourse/01_Datasets/user_parq.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+---------+-------------+------+------+\n",
      "|First_Name|Middle_Name|Last_Name|Date_of_Birth|Gender|Salary|\n",
      "+----------+-----------+---------+-------------+------+------+\n",
      "|     James|           |    Smith|   1991-04-01|     M|  3000|\n",
      "|   Michael|       Rose|         |   2000-05-19|     M|  4000|\n",
      "|    Robert|           | Williams|   1978-09-05|     M|  4000|\n",
      "|     Maria|       Anne|    Jones|   1967-12-01|     F|  4000|\n",
      "|       Jen|       Mary|    Brown|   1980-02-17|     F|    -1|\n",
      "+----------+-----------+---------+-------------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfp=spark.read.parquet(\"file:///SparkCourse/01_Datasets/user_parq.parquet\")\n",
    "dfp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+---------+-------------+------+------+\n",
      "|First_Name|Middle_Name|Last_Name|Date_of_Birth|Gender|Salary|\n",
      "+----------+-----------+---------+-------------+------+------+\n",
      "|     James|           |    Smith|   1991-04-01|     M|  3000|\n",
      "|   Michael|       Rose|         |   2000-05-19|     M|  4000|\n",
      "|    Robert|           | Williams|   1978-09-05|     M|  4000|\n",
      "|     Maria|       Anne|    Jones|   1967-12-01|     F|  4000|\n",
      "|       Jen|       Mary|    Brown|   1980-02-17|     F|    -1|\n",
      "+----------+-----------+---------+-------------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import DataFrameWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.mode('append').parquet(\"file:///SparkCourse/01_Datasets/user_parq.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.mode('overwrite').parquet(\"file:///SparkCourse/01_Datasets/user_parq.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Executing SQL Queries on DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  pyspark sql create temporary view on paraquet files to execute sql queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView('ParquetTable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "parksql=spark.sql('select * from ParquetTable where salary >=4000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+---------+-------------+------+------+\n",
      "|First_Name|Middle_Name|Last_Name|Date_of_Birth|Gender|Salary|\n",
      "+----------+-----------+---------+-------------+------+------+\n",
      "|   Michael|       Rose|         |   2000-05-19|     M|  4000|\n",
      "|    Robert|           | Williams|   1978-09-05|     M|  4000|\n",
      "|     Maria|       Anne|    Jones|   1967-12-01|     F|  4000|\n",
      "+----------+-----------+---------+-------------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parksql.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------+--------------+--------------+-----------------+--------------------+-------------+--------------+----------------+\n",
      "|customer_id|customer_fname|customer_lname|customer_email|customer_password|     customer_street|customer_city|customer_state|customer_zipcode|\n",
      "+-----------+--------------+--------------+--------------+-----------------+--------------------+-------------+--------------+----------------+\n",
      "|          1|       Richard|     Hernandez|     XXXXXXXXX|        XXXXXXXXX|  6303 Heather Plaza|  Brownsville|            TX|           78521|\n",
      "|        526|      Kimberly|       Barrett|     XXXXXXXXX|        XXXXXXXXX|     7988 High Jetty|  Brownsville|            TX|           78521|\n",
      "|       4294|   Christopher|      Espinoza|     XXXXXXXXX|        XXXXXXXXX|      3737 Blue Path|  Brownsville|            TX|           78521|\n",
      "|       4963|          Mary|         Smith|     XXXXXXXXX|        XXXXXXXXX|     1325 Noble Pike|  Brownsville|            TX|           78521|\n",
      "|       7063|          Mary|         Smith|     XXXXXXXXX|        XXXXXXXXX|     472 Noble Mall |  Brownsville|            TX|           78521|\n",
      "|       9733|         Marie|        Acosta|     XXXXXXXXX|        XXXXXXXXX|5459 Noble Brook ...|  Brownsville|            TX|           78521|\n",
      "|       9761|         Helen|         Smith|     XXXXXXXXX|        XXXXXXXXX|8927 Merry Elk Ce...|  Brownsville|            TX|           78521|\n",
      "|       9963|           Roy|       Merritt|     XXXXXXXXX|        XXXXXXXXX|     3278 Misty Port|  Brownsville|            TX|           78521|\n",
      "|      10942|        Donald|         Smith|     XXXXXXXXX|        XXXXXXXXX| 1674 Lost Diversion|  Brownsville|            TX|           78521|\n",
      "+-----------+--------------+--------------+--------------+-----------------+--------------------+-------------+--------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parquet.createOrReplaceTempView('table')\n",
    "pyspark_sql=spark.sql('select * from table where  customer_zipcode= 78521 ')\n",
    "pyspark_sql.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql('create temporary view person11 using parquet options (path \\\"file:///SparkCourse/01_Datasets/customer_parq.parquet\\\")')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------+--------------+--------------+-----------------+--------------------+-------------+--------------+----------------+\n",
      "|customer_id|customer_fname|customer_lname|customer_email|customer_password|     customer_street|customer_city|customer_state|customer_zipcode|\n",
      "+-----------+--------------+--------------+--------------+-----------------+--------------------+-------------+--------------+----------------+\n",
      "|          1|       Richard|     Hernandez|     XXXXXXXXX|        XXXXXXXXX|  6303 Heather Plaza|  Brownsville|            TX|           78521|\n",
      "|          2|          Mary|       Barrett|     XXXXXXXXX|        XXXXXXXXX|9526 Noble Embers...|    Littleton|            CO|           80126|\n",
      "|          3|           Ann|         Smith|     XXXXXXXXX|        XXXXXXXXX|3422 Blue Pioneer...|       Caguas|            PR|           00725|\n",
      "|          4|          Mary|         Jones|     XXXXXXXXX|        XXXXXXXXX|  8324 Little Common|   San Marcos|            CA|           92069|\n",
      "|          5|        Robert|        Hudson|     XXXXXXXXX|        XXXXXXXXX|10 Crystal River ...|       Caguas|            PR|           00725|\n",
      "|          6|          Mary|         Smith|     XXXXXXXXX|        XXXXXXXXX|3151 Sleepy Quail...|      Passaic|            NJ|           07055|\n",
      "|          7|       Melissa|        Wilcox|     XXXXXXXXX|        XXXXXXXXX|9453 High Concession|       Caguas|            PR|           00725|\n",
      "|          8|         Megan|         Smith|     XXXXXXXXX|        XXXXXXXXX|3047 Foggy Forest...|     Lawrence|            MA|           01841|\n",
      "|          9|          Mary|         Perez|     XXXXXXXXX|        XXXXXXXXX| 3616 Quaking Street|       Caguas|            PR|           00725|\n",
      "|         10|       Melissa|         Smith|     XXXXXXXXX|        XXXXXXXXX|8598 Harvest Beac...|     Stafford|            VA|           22554|\n",
      "|         11|          Mary|       Huffman|     XXXXXXXXX|        XXXXXXXXX|    3169 Stony Woods|       Caguas|            PR|           00725|\n",
      "|         12|   Christopher|         Smith|     XXXXXXXXX|        XXXXXXXXX|5594 Jagged Ember...|  San Antonio|            TX|           78227|\n",
      "|         13|          Mary|       Baldwin|     XXXXXXXXX|        XXXXXXXXX|7922 Iron Oak Gar...|       Caguas|            PR|           00725|\n",
      "|         14|     Katherine|         Smith|     XXXXXXXXX|        XXXXXXXXX|5666 Hazy Pony Sq...|  Pico Rivera|            CA|           90660|\n",
      "|         15|          Jane|          Luna|     XXXXXXXXX|        XXXXXXXXX|    673 Burning Glen|      Fontana|            CA|           92336|\n",
      "|         16|       Tiffany|         Smith|     XXXXXXXXX|        XXXXXXXXX|      6651 Iron Port|       Caguas|            PR|           00725|\n",
      "|         17|          Mary|      Robinson|     XXXXXXXXX|        XXXXXXXXX|     1325 Noble Pike|       Taylor|            MI|           48180|\n",
      "|         18|        Robert|         Smith|     XXXXXXXXX|        XXXXXXXXX|2734 Hazy Butterf...|     Martinez|            CA|           94553|\n",
      "|         19|     Stephanie|      Mitchell|     XXXXXXXXX|        XXXXXXXXX|3543 Red Treasure...|       Caguas|            PR|           00725|\n",
      "|         20|          Mary|         Ellis|     XXXXXXXXX|        XXXXXXXXX|      4703 Old Route|West New York|            NJ|           07093|\n",
      "+-----------+--------------+--------------+--------------+-----------------+--------------------+-------------+--------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('select * from person11').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+--------+----+----------+\n",
      "|  Address|Boolean|  Mobile|Name|      Pets|\n",
      "+---------+-------+--------+----+----------+\n",
      "|[USA, AU]|   true|12345678|Test|[Dog, cat]|\n",
      "+---------+-------+--------+----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df33.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
